# Building KPI Assessment Agents in Antigravity with Memory Context
## Complete Implementation Guide with MemVid Integration

---

## üéØ OVERVIEW: System Architecture with Memory

### The Brain-Like System We're Building
```
Document Input (5 types)
    ‚Üì
Agents Read & Process (with memory context)
    ‚Üì
Store Important Information (in agent memory)
    ‚Üì
Use Memory Context (for multi-layer analysis)
    ‚Üì
Make Decisions (informed by stored context)
    ‚Üì
Generate Report (with evidence from memory)
```

### Why Memory Matters
- Agents need to "remember" baseline data while analyzing peers
- Agents need to "remember" achievement history while assessing credibility
- Agents need to "remember" governance structure while evaluating achievability
- Agents need to cross-reference information across 5 documents

---

## üìö MEMORY INTEGRATION STRATEGY

### MemVid Integration (Knowledge Base)
```
MemVid acts as the agent's "brain memory":
1. Document reading ‚Üí Extract key facts
2. Store in MemVid ‚Üí Indexed, searchable knowledge base
3. Agents query memory ‚Üí "What was the baseline?" "What's the track record?"
4. Memory context ‚Üí Informs all downstream analysis
5. Cross-document validation ‚Üí Uses memory to verify consistency
```

### Memory Architecture
```
Agent Memory Structure:
‚îú‚îÄ Company Profile Memory
‚îÇ  ‚îú‚îÄ Name, sector, size, geography
‚îÇ  ‚îú‚îÄ Key identifiers (NACE code, revenue, employees)
‚îÇ  ‚îî‚îÄ Contact/submission date
‚îÇ
‚îú‚îÄ Baseline Memory
‚îÇ  ‚îú‚îÄ Current metrics (with units, years)
‚îÇ  ‚îú‚îÄ Historical values (2019-2024)
‚îÇ  ‚îú‚îÄ Verification status (audited? by whom? when?)
‚îÇ  ‚îú‚îÄ Trend analysis (improving/stable/declining)
‚îÇ  ‚îî‚îÄ Red flags (baseline jumps, scope changes)
‚îÇ
‚îú‚îÄ Achievement Memory
‚îÇ  ‚îú‚îÄ Prior targets (value, year, baseline year)
‚îÇ  ‚îú‚îÄ Actual achievements (value, year, status)
‚îÇ  ‚îú‚îÄ Success rate calculation
‚îÇ  ‚îú‚îÄ Pattern identification
‚îÇ  ‚îî‚îÄ Credibility signals
‚îÇ
‚îú‚îÄ Governance Memory
‚îÇ  ‚îú‚îÄ Board structure (members, independence, oversight)
‚îÇ  ‚îú‚îÄ CEO/CFO incentives (tied to KPI? bonus? vesting?)
‚îÇ  ‚îú‚îÄ Sustainability team (size, budget, reporting)
‚îÇ  ‚îî‚îÄ Accountability mechanisms
‚îÇ
‚îú‚îÄ Capex Memory
‚îÇ  ‚îú‚îÄ Budget amount (‚Ç¨ committed)
‚îÇ  ‚îú‚îÄ Allocation by project (kiln retrofit, renewable, etc.)
‚îÇ  ‚îú‚îÄ Timeline (2025-2030 phasing)
‚îÇ  ‚îú‚îÄ Funding source (internal/bond/external)
‚îÇ  ‚îî‚îÄ Cost per unit (‚Ç¨/tCO2e, ‚Ç¨/MW, etc.)
‚îÇ
‚îú‚îÄ Peer Comparison Memory
‚îÇ  ‚îú‚îÄ Sector benchmarks (average, median, percentiles)
‚îÇ  ‚îú‚îÄ Size-adjusted metrics
‚îÇ  ‚îú‚îÄ Geographic comparables
‚îÇ  ‚îú‚îÄ Actual peer companies (names, targets, financials)
‚îÇ  ‚îî‚îÄ Peer percentile rank
‚îÇ
‚îú‚îÄ Regulatory Memory
‚îÇ  ‚îú‚îÄ EU Taxonomy requirements (for this sector)
‚îÇ  ‚îú‚îÄ CSRD compliance (12 standards coverage)
‚îÇ  ‚îú‚îÄ SBTi validation status
‚îÇ  ‚îî‚îÄ Gaps and red flags
‚îÇ
‚îî‚îÄ Risk & Achievability Memory
   ‚îú‚îÄ Execution risks (identified)
   ‚îú‚îÄ Market risks (commodity prices, technology)
   ‚îú‚îÄ Financing risks
   ‚îú‚îÄ Mitigation strategies
   ‚îî‚îÄ Overall risk score
```

---

## üîß BUILDING IN ANTIGRAVITY

### Step 1: Setup Antigravity Environment

```yaml
# antigravity-config.yaml
project: kpi_assessment_agents
version: 2.0
environment: production

integrations:
  - name: memvid
    api_endpoint: https://api.memvid.com
    version: v1
    authentication: api_key
    
  - name: anthropic
    model: claude-3-5-sonnet-20241022
    version: latest
    
  - name: eurostat
    endpoint: https://ec.europa.eu/eurostat/api
    
  - name: sbti
    endpoint: https://sciencebasedtargets.org/api
    
  - name: eu_taxonomy
    endpoint: https://eu-taxonomy-database.api

agents:
  tier_1: 5  # Document Intelligence
  tier_2: 3  # Data Extraction
  tier_3: 4  # Benchmarking (with memory)
  tier_4: 4  # Analysis & Synthesis
  tier_5: 1  # Orchestration
  
memory:
  type: memvid
  max_context_tokens: 50000
  retention_days: 365
  indexing: semantic
```

### Step 2: Memory-Enabled Agent Base Class

```python
# agents/base_agent_with_memory.py
from typing import Optional, Dict, Any, List
import anthropic
import memvid
from datetime import datetime
import json

class MemoryStore:
    """Wrapper for MemVid integration"""
    
    def __init__(self, api_key: str, company_id: str):
        self.client = memvid.Client(api_key=api_key)
        self.company_id = company_id
        self.memory_index = f"kpi_assessment_{company_id}"
        
    async def store_fact(self, category: str, key: str, value: Any, 
                        metadata: Optional[Dict] = None):
        """Store a fact in memory with semantic indexing"""
        fact = {
            "category": category,  # baseline, achievement, governance, etc.
            "key": key,
            "value": value,
            "timestamp": datetime.now().isoformat(),
            "metadata": metadata or {}
        }
        
        # Store in MemVid with semantic indexing
        await self.client.memories.store(
            index=self.memory_index,
            document_id=f"{category}_{key}",
            content=json.dumps(fact),
            metadata={"category": category, "type": key}
        )
    
    async def retrieve_memory(self, query: str, category: Optional[str] = None) -> List[Dict]:
        """Retrieve memories using semantic search"""
        filters = {}
        if category:
            filters["category"] = category
        
        results = await self.client.memories.search(
            index=self.memory_index,
            query=query,
            filters=filters,
            top_k=10
        )
        
        return [json.loads(r["content"]) for r in results]
    
    async def get_memory_context(self, agent_name: str) -> str:
        """Get full memory context for an agent to reference"""
        all_memories = await self.client.memories.list(
            index=self.memory_index
        )
        
        context = f"Memory Context for {agent_name}:\n\n"
        for memory in all_memories:
            fact = json.loads(memory["content"])
            context += f"[{fact['category']}] {fact['key']}: {fact['value']}\n"
        
        return context


class BaseAgentWithMemory:
    """Base agent with integrated memory"""
    
    def __init__(self, name: str, company_id: str, memory_store: MemoryStore):
        self.name = name
        self.company_id = company_id
        self.memory = memory_store
        self.llm = anthropic.Anthropic()
        self.agent_logs = []
    
    async def think_with_memory(self, task: str, context_categories: List[str]) -> str:
        """
        Agent thinks through a task with memory context
        This is how the agent "reasons" like a banker
        """
        
        # Step 1: Retrieve relevant memory context
        memory_context = await self.memory.get_memory_context(self.name)
        
        # Step 2: Filter memory to relevant categories
        relevant_memory = ""
        for category in context_categories:
            memories = await self.memory.retrieve_memory(
                query=task,
                category=category
            )
            if memories:
                relevant_memory += f"\n[{category.upper()}]\n"
                for mem in memories:
                    relevant_memory += f"- {mem['key']}: {mem['value']}\n"
        
        # Step 3: Ask Claude with memory context
        prompt = f"""You are a KPI assessment agent named {self.name}.
You have access to the following memory context about this company:

{relevant_memory}

Now, {task}

Remember to reference the memory context in your reasoning.
Be specific and cite facts from memory."""
        
        response = await self.llm.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=2000,
            messages=[{"role": "user", "content": prompt}]
        )
        
        thought_process = response.content[0].text
        
        # Log the thinking process
        self.agent_logs.append({
            "timestamp": datetime.now().isoformat(),
            "agent": self.name,
            "task": task,
            "thought_process": thought_process,
            "memory_used": context_categories
        })
        
        return thought_process
    
    async def remember(self, category: str, key: str, value: Any, 
                      metadata: Optional[Dict] = None):
        """Agent stores something in memory"""
        await self.memory.store_fact(category, key, value, metadata)
        
        self.agent_logs.append({
            "timestamp": datetime.now().isoformat(),
            "agent": self.name,
            "action": "remember",
            "category": category,
            "key": key
        })
```

---

## üìñ TIER 1: DOCUMENT INTELLIGENCE AGENTS (With Memory)

### Agent 1: Document Processor with Memory

```python
# agents/tier1/agent1_document_processor.py
from base_agent_with_memory import BaseAgentWithMemory
import fitz
import json
from typing import Dict

class DocumentProcessorAgent(BaseAgentWithMemory):
    """
    Reads 5 documents and stores key facts in memory
    Acts like a human reading and remembering important points
    """
    
    async def process_documents(self, file_paths: Dict[str, str]) -> Dict:
        """
        Process all 5 document types
        file_paths = {
            'csrd': 'path/to/csrd.pdf',
            'annual': 'path/to/annual.pdf',
            'sustainability': 'path/to/sustainability.pdf',
            'third_party': 'path/to/third_party_opinion.pdf',
            'transition_plan': 'path/to/transition_plan.pdf'
        }
        """
        
        print(f"üìñ {self.name}: Starting to read all 5 documents...")
        
        extracted_documents = {}
        
        for doc_type, file_path in file_paths.items():
            print(f"\n  Reading {doc_type}...")
            
            # Extract text from PDF
            doc = fitz.open(file_path)
            full_text = ""
            for page_num, page in enumerate(doc):
                full_text += f"\n[PAGE {page_num + 1}]\n{page.get_text()}"
            doc.close()
            
            extracted_documents[doc_type] = {
                'raw_text': full_text,
                'page_count': len(doc),
                'file_path': file_path
            }
            
            # Store in memory: Document metadata
            await self.remember(
                category="document_metadata",
                key=f"{doc_type}_summary",
                value={
                    'type': doc_type,
                    'pages': len(doc),
                    'status': 'processed'
                }
            )
        
        # Now let Claude read across documents and extract key facts
        print(f"\n  {self.name}: Analyzing documents with AI...")
        
        analysis_prompt = f"""You are reading 5 company documents:
1. CSRD Report (regulatory disclosure)
2. Annual Report (financial & operations)
3. Sustainability Report (environmental claims)
4. Third-Party Opinion (verification)
5. Transition Plan (future roadmap)

Across all documents, identify and extract:

COMPANY BASICS:
- Company name
- Sector (NACE code if visible)
- Revenue/size
- Geographic presence

BASELINE METRICS:
- Current emissions/metrics (with year)
- Historical values (multi-year trend)
- Measurement methodology

KPI TARGETS:
- Proposed target value
- Target year
- Baseline year for comparison
- Scope (if emissions: Scope 1/2/3?)

GOVERNANCE:
- Board oversight mentioned?
- CEO/CFO ESG incentives?
- Dedicated sustainability officer?

CAPEX:
- Any capex commitments mentioned?
- Budget amounts?
- Project descriptions?

VERIFICATION:
- Is baseline data audited?
- By whom? When?
- Any third-party opinions?

Return as JSON with these exact keys."""
        
        # Extract across all documents
        extraction_task = f"""Analyze these 5 documents:
{json.dumps({k: v['raw_text'][:2000] + "..." for k, v in extracted_documents.items()})}

Extract key facts following the JSON structure above."""
        
        extracted_facts = await self.think_with_memory(
            task=extraction_task,
            context_categories=["document_metadata"]
        )
        
        # Parse and store extracted facts in memory
        try:
            facts = json.loads(extracted_facts)
            
            # Store company basics
            for key, value in facts.get('company_basics', {}).items():
                await self.remember("company_basics", key, value)
            
            # Store baseline metrics
            for key, value in facts.get('baseline_metrics', {}).items():
                await self.remember("baseline", key, value)
            
            # Store KPI targets
            for key, value in facts.get('kpi_targets', {}).items():
                await self.remember("target", key, value)
            
            # Store governance
            for key, value in facts.get('governance', {}).items():
                await self.remember("governance", key, value)
            
            # Store capex
            for key, value in facts.get('capex', {}).items():
                await self.remember("capex", key, value)
            
            # Store verification
            for key, value in facts.get('verification', {}).items():
                await self.remember("verification", key, value)
            
        except json.JSONDecodeError:
            print(f"Warning: Could not parse extraction as JSON")
            # Store raw extraction
            await self.remember("raw_extraction", "agent1_analysis", extracted_facts)
        
        print(f"\n‚úÖ {self.name}: Stored all key facts in memory")
        return extracted_documents


# Usage in Antigravity:
async def run_agent1():
    memory = MemoryStore(api_key="your_memvid_key", company_id="company_123")
    
    agent1 = DocumentProcessorAgent(
        name="DocumentProcessorAgent",
        company_id="company_123",
        memory_store=memory
    )
    
    docs = await agent1.process_documents({
        'csrd': 'documents/csrd.pdf',
        'annual': 'documents/annual.pdf',
        'sustainability': 'documents/sustainability.pdf',
        'third_party': 'documents/third_party.pdf',
        'transition_plan': 'documents/transition_plan.pdf'
    })
    
    return agent1.agent_logs
```

### Agent 4: Achievement Tracker with Memory

```python
# agents/tier1/agent4_achievement_tracker.py
from base_agent_with_memory import BaseAgentWithMemory

class AchievementTrackerAgent(BaseAgentWithMemory):
    """
    Reads prior targets and achievements
    Stores track record in memory
    Informs credibility assessment
    """
    
    async def extract_achievement_history(self, state) -> Dict:
        """Extract 5-year achievement history"""
        
        print(f"üìä {self.name}: Analyzing prior targets and achievements...")
        
        # Get company name from memory
        company_info = await self.memory.retrieve_memory(
            query="company name sector"
        )
        
        company_name = company_info[0]['value']['name'] if company_info else "Unknown"
        
        # Task with memory context
        task = f"""For {company_name}, extract ALL prior sustainability targets from the last 5 years:

For EACH prior target, provide:
- Target value (e.g., 5%)
- Target year (when to achieve it)
- Baseline year
- Actual achievement (what was actually achieved)
- Achievement status (exceeded/met/missed/greatly_missed)
- Timeline status (early/on-time/late)
- Any corrective actions mentioned

Then calculate:
1. Total success rate (% of targets met or exceeded)
2. Pattern: Consistent/Improving/Declining/Sporadic
3. Credibility signals (strong/moderate/weak)

Return as JSON with array of targets and summary metrics."""
        
        achievement_analysis = await self.think_with_memory(
            task=task,
            context_categories=["company_basics", "baseline", "target"]
        )
        
        try:
            achievements = json.loads(achievement_analysis)
            
            # Store each prior target in memory
            for i, target in enumerate(achievements.get('prior_targets', [])):
                await self.remember(
                    category="achievement",
                    key=f"prior_target_{i+1}",
                    value=target,
                    metadata={"status": target.get('status')}
                )
            
            # Store summary metrics
            await self.remember(
                category="achievement",
                key="success_rate",
                value=achievements.get('success_rate', 0)
            )
            
            await self.remember(
                category="achievement",
                key="pattern",
                value=achievements.get('pattern', 'unknown')
            )
            
            await self.remember(
                category="achievement",
                key="credibility_score",
                value=achievements.get('credibility_score', 0)
            )
            
        except json.JSONDecodeError:
            await self.remember("raw_extraction", "agent4_analysis", achievement_analysis)
        
        print(f"‚úÖ {self.name}: Stored achievement history in memory")
        return achievements
```

---

## üîç TIER 3: BENCHMARKING AGENTS (The Memory Power)

### Agent 9: 5-Layer Peer Benchmarking with Memory

```python
# agents/tier3/agent9_peer_benchmarking.py
from base_agent_with_memory import BaseAgentWithMemory
import httpx

class MultiLayerPeerBenchmarkAgent(BaseAgentWithMemory):
    """
    5-layer benchmarking that uses memory context
    Layers build on each other, with memory helping understand context
    """
    
    async def execute_5_layer_benchmark(self) -> Dict:
        """
        Execute 5-layer benchmarking using memory
        Each layer references previous layer from memory
        """
        
        print(f"\nüìä {self.name}: Starting 5-layer benchmarking...")
        
        # Get company basics from memory
        company_memory = await self.memory.retrieve_memory(
            query="company sector size revenue employees"
        )
        
        company_data = {mem['value'] for mem in company_memory}
        
        # Get target from memory
        target_memory = await self.memory.retrieve_memory(
            query="KPI target value year"
        )
        
        target_data = target_memory[0]['value'] if target_memory else {}
        
        # LAYER 1: SECTOR BENCHMARK
        print("  Layer 1: Getting sector benchmark from Eurostat...")
        
        layer1_task = f"""Based on company memory:
        
Company sector: {[m['value'] for m in company_memory if m['key'] == 'sector']}

Task:
1. Identify the NACE code for this sector
2. Query Eurostat for sector average reduction targets
3. Get median, 25th percentile, 75th percentile
4. Compare company target against sector

Use this format:
{{
    "sector_average": X%,
    "sector_median": X%,
    "sector_p25": X%,
    "sector_p75": X%,
    "company_vs_sector": "ABOVE/BELOW/EQUAL",
    "assessment": "..."
}}"""
        
        layer1_result = await self.think_with_memory(
            task=layer1_task,
            context_categories=["company_basics", "target"]
        )
        
        await self.remember("benchmark", "layer1_sector", json.loads(layer1_result))
        
        # LAYER 2: SIZE ADJUSTMENT
        print("  Layer 2: Adjusting for company size...")
        
        layer2_task = f"""Using memory:
Company revenue: {[m['value'] for m in company_memory if m['key'] == 'revenue']}
Company baseline: {[m['value'] for m in await self.memory.retrieve_memory('baseline emissions')]}

Task:
1. Calculate intensity metrics (tCO2e / ‚Ç¨ revenue, tCO2e / employee)
2. Find peer group of similar-sized companies
3. Compare company metrics against size-adjusted peers
4. Assess if target is appropriate for company size

Return: {{
    "company_intensity": X,
    "peer_intensity_avg": X,
    "size_cohort_percentile": X,
    "assessment": "..."
}}"""
        
        layer2_result = await self.think_with_memory(
            task=layer2_task,
            context_categories=["company_basics", "baseline", "target"]
        )
        
        await self.remember("benchmark", "layer2_size", json.loads(layer2_result))
        
        # LAYER 3: GEOGRAPHY
        print("  Layer 3: Adjusting for geography...")
        
        layer3_task = """Get company geography from memory.
Task: 
1. Identify country and region
2. Get energy mix data (% renewable) for that country
3. Identify EU vs non-EU context
4. Compare to regional peers
5. Assess if target is appropriate for geography

Return: {
    "country": "...",
    "energy_mix_renewable": X%,
    "regional_average": X%,
    "assessment": "..."
}"""
        
        layer3_result = await self.think_with_memory(
            task=layer3_task,
            context_categories=["company_basics"]
        )
        
        await self.remember("benchmark", "layer3_geography", json.loads(layer3_result))
        
        # LAYER 4: COMPARABLE PEERS
        print("  Layer 4: Finding comparable peer group...")
        
        layer4_task = """From memory:
- Company sector (from Layer 1)
- Company size (from Layer 2)
- Company geography (from Layer 3)

Task:
1. Use memory to define peer criteria
2. Search for 10-20 comparable public companies
3. Get their KPI targets (from CSRD disclosures, SBTi database)
4. Calculate peer percentiles (25th, 50th, 75th)
5. Determine company percentile rank
6. Assess: Is company target ambitious, moderate, or weak?

Return: {
    "peer_count": X,
    "peer_targets": [X%, Y%, Z%, ...],
    "peer_p25": X%,
    "peer_p50": X%,
    "peer_p75": X%,
    "company_percentile_rank": X,
    "assessment": "WEAK/MODERATE/AMBITIOUS"
}"""
        
        layer4_result = await self.think_with_memory(
            task=layer4_task,
            context_categories=["benchmark", "company_basics", "target"]
        )
        
        await self.remember("benchmark", "layer4_peers", json.loads(layer4_result))
        
        # LAYER 5: PATHWAY ALIGNMENT
        print("  Layer 5: Checking EU Taxonomy & climate pathway alignment...")
        
        layer5_task = """From memory:
- Company sector
- Company target
- Peer benchmarking results

Task:
1. Get EU Taxonomy requirement for sector
2. Check if target aligns with Taxonomy pathway
3. Check 1.5¬∞C warming alignment
4. Assess SBTi validation status
5. Gap analysis: What's needed for AMBITIOUS?

Return: {
    "eu_taxonomy_requirement": X%,
    "gap_to_taxonomy": X,
    "sbti_aligned": true/false,
    "assessment": "ALIGNED/PARTIALLY_ALIGNED/NOT_ALIGNED"
}"""
        
        layer5_result = await self.think_with_memory(
            task=layer5_task,
            context_categories=["benchmark", "company_basics", "target"]
        )
        
        await self.remember("benchmark", "layer5_pathway", json.loads(layer5_result))
        
        # SYNTHESIS: Combine all layers
        print("  Synthesizing across all 5 layers...")
        
        synthesis_task = """From memory, you have analyzed:
- Layer 1: Sector benchmark
- Layer 2: Company size adjustment
- Layer 3: Geography adjustment
- Layer 4: Comparable peer group
- Layer 5: EU Taxonomy pathway

Task: Synthesize into final assessment:
1. Is company target WEAK / MODERATE / AMBITIOUS?
2. Confidence level (0-100%)?
3. Key evidence supporting this?
4. What would be needed for next level?

Return: {
    "final_assessment": "WEAK/MODERATE/AMBITIOUS",
    "confidence": X,
    "evidence": ["...", "...", "..."],
    "gap_to_ambitious": "Y percentage points"
}"""
        
        synthesis = await self.think_with_memory(
            task=synthesis_task,
            context_categories=["benchmark"]
        )
        
        await self.remember("benchmark", "synthesis", json.loads(synthesis))
        
        print(f"‚úÖ {self.name}: Complete 5-layer benchmark with memory context stored")
        
        return {
            'layer1': layer1_result,
            'layer2': layer2_result,
            'layer3': layer3_result,
            'layer4': layer4_result,
            'layer5': layer5_result,
            'synthesis': synthesis
        }
```

---

## üéØ TIER 5: ORCHESTRATOR WITH MEMORY

```python
# agents/tier5/orchestrator_with_memory.py
from base_agent_with_memory import BaseAgentWithMemory

class OrchestratorAgentWithMemory(BaseAgentWithMemory):
    """
    Orchestrates all 17 agents
    Uses memory to cross-reference all findings
    Makes final banker-style recommendation
    """
    
    async def run_full_assessment(self, file_paths: Dict[str, str]) -> Dict:
        """
        Run complete assessment using memory context
        """
        
        print("\n" + "="*60)
        print("üöÄ ORCHESTRATOR: Starting full KPI assessment")
        print("="*60)
        
        # Phase 1: Document Intelligence (Agents 1-5)
        print("\nüìñ PHASE 1: Document Intelligence (Tier 1)")
        
        # Agent 1: Document Processor
        agent1 = DocumentProcessorAgent("Agent1_DocumentProcessor", 
                                       self.company_id, self.memory)
        docs = await agent1.process_documents(file_paths)
        
        # Agent 4: Achievement Tracker
        agent4 = AchievementTrackerAgent("Agent4_AchievementTracker",
                                        self.company_id, self.memory)
        achievements = await agent4.extract_achievement_history(None)
        
        # (Agents 2, 3, 5 run similarly...)
        
        # Phase 2: Data Extraction (Agents 6-8)
        print("\nüîç PHASE 2: Data Extraction (Tier 2)")
        # Extract KPI, governance, capex (all store in memory)
        
        # Phase 3: Benchmarking (Agents 9-12) ‚Üê USES MEMORY
        print("\nüìä PHASE 3: Benchmarking with Memory Context (Tier 3)")
        
        agent9 = MultiLayerPeerBenchmarkAgent("Agent9_5LayerBenchmark",
                                             self.company_id, self.memory)
        benchmark = await agent9.execute_5_layer_benchmark()
        
        # Phase 4: Analysis (Agents 13-16)
        print("\nüí° PHASE 4: Analysis & Synthesis (Tier 4)")
        # Use memory to synthesize all findings
        
        # Phase 5: Final Decision
        print("\n‚úÖ PHASE 5: Final Recommendation")
        
        final_task = """Using ALL memory context from previous analyses:

Memory contains:
- Company baseline and metrics
- Achievement history and credibility
- 5-layer peer benchmarking results
- Governance assessment
- Capex credibility
- Risk assessment

Task: Provide final BANKER's recommendation:

1. ASSESSMENT: Is this WEAK / MODERATE / AMBITIOUS?
2. CONFIDENCE: How confident? (0-100%)
3. RECOMMENDATION: REJECT / CONDITIONAL_APPROVAL / FULL_APPROVAL?
4. PRICING: Standard rate / Green premium / Risk adjustment?
5. CONDITIONS: What conditions for approval?
6. NEXT STEPS: What should banker do?

Remember: Think like a banker using all evidence from memory."""
        
        final_decision = await self.think_with_memory(
            task=final_task,
            context_categories=["benchmark", "achievement", "governance", 
                               "capex", "baseline", "target"]
        )
        
        await self.remember("decision", "final_recommendation", final_decision)
        
        print(f"\n{'='*60}")
        print("‚úÖ ASSESSMENT COMPLETE")
        print(f"{'='*60}")
        
        # Generate comprehensive report
        report = await self._generate_report()
        
        return {
            'decision': final_decision,
            'report': report,
            'memory_logs': self.agent_logs
        }
    
    async def _generate_report(self) -> str:
        """Generate final report using all stored memory"""
        
        # Retrieve all memories
        all_memories = await self.memory.retrieve_memory(query="*")
        
        report = "# KPI ASSESSMENT FINAL REPORT\n\n"
        
        # Executive Summary
        decision_mem = await self.memory.retrieve_memory(
            query="final recommendation assessment confidence"
        )
        
        report += "## EXECUTIVE SUMMARY\n"
        report += f"{decision_mem[0]['value']}\n\n"
        
        # Baseline Section
        baseline_mem = await self.memory.retrieve_memory(category="baseline")
        report += "## BASELINE VERIFICATION\n"
        for mem in baseline_mem:
            report += f"- {mem['key']}: {mem['value']}\n"
        
        # (Continue for each section using memory)
        
        return report
```

---

## üîó INTEGRATING WITH ANTIGRAVITY WORKFLOWS

### Antigravity Agent Configuration

```yaml
# antigravity/agents/kpi_assessment.yaml
agents:
  - name: DocumentProcessor
    type: "memory_agent"
    memory_backend: "memvid"
    memory_config:
      api_endpoint: "https://api.memvid.com"
      api_key: "${MEMVID_API_KEY}"
      index_name: "kpi_assessment"
      retention_days: 365
    
    llm_config:
      provider: "anthropic"
      model: "claude-3-5-sonnet-20241022"
      temperature: 0.7
      max_tokens: 2000
    
    capabilities:
      - document_reading
      - pdf_extraction
      - memory_storage
      - fact_extraction
    
    memory_categories:
      - company_basics
      - baseline
      - target
      - achievement
      - governance
      - capex
      - verification
  
  - name: PeerBenchmarkAgent
    type: "memory_agent"
    memory_backend: "memvid"
    
    api_integrations:
      - name: "eurostat"
        endpoint: "https://ec.europa.eu/eurostat/api"
      - name: "sbti"
        endpoint: "https://sciencebasedtargets.org/api"
      - name: "eu_taxonomy"
        endpoint: "https://eu-taxonomy.api"
    
    memory_dependencies:
      - "company_basics"  # reads from memory
      - "baseline"        # reads from memory
      - "target"          # reads from memory
    
    memory_outputs:
      - "layer1_sector"
      - "layer2_size"
      - "layer3_geography"
      - "layer4_peers"
      - "layer5_pathway"
      - "synthesis"
    
    five_layer_benchmarking: true
  
  - name: OrchestratorAgent
    type: "memory_agent"
    memory_backend: "memvid"
    
    orchestrates:
      - "DocumentProcessor"
      - "ChartAnalyzer"
      - "BaselineVerifier"
      - "AchievementTracker"
      - "CompletenessAnalyzer"
      - "KPIExtractor"
      - "GovernanceExtractor"
      - "CapexExtractor"
      - "PeerBenchmarkAgent"
      - "TaxonomyAlignmentAgent"
      - "CSRDComplianceAgent"
      - "SBTiValidationAgent"
      - "RiskAssessmentAgent"
      - "SynthesisAgent"
      - "ChartGenerationAgent"
      - "ImageGenerationAgent"
    
    memory_operations:
      - retrieve_all_context  # Get complete memory before final decision
      - cross_validate        # Validate consistency across memory
      - synthesize            # Combine all findings
      - generate_report       # Create final report
    
    output_format: "pdf_report"
```

---

## üìä MEMORY CONTEXT FLOW DIAGRAM

```
DOCUMENT INPUT
    ‚Üì
Agent 1 reads CSRD, Annual, etc.
    ‚Üì stores key facts
MEMORY (MemVid)
    ‚Üë retrieved by Agent 4
Agent 4 reads achievement history
    ‚Üì stores track record
MEMORY updates
    ‚Üë retrieved by Agent 9
Agent 9 Layer 1: Reads company sector from memory
    ‚Üì
Agent 9 Layer 2: Reads company size from memory
    ‚Üì
Agent 9 Layer 3: Reads company geography from memory
    ‚Üì
Agent 9 Layer 4: Builds peer group using memory context
    ‚Üì
Agent 9 Layer 5: Aligns with pathways using all memory
    ‚Üì stores complete benchmark
MEMORY updates
    ‚Üë retrieved by Orchestrator
Orchestrator: Retrieves ALL memory for final decision
    ‚Üì
FINAL RECOMMENDATION + REPORT
```

---

## üöÄ DEPLOYING IN ANTIGRAVITY

### Step 1: Setup Memory Infrastructure

```bash
# Initialize MemVid integration
antigravity init-memory \
  --provider memvid \
  --api-key ${MEMVID_API_KEY} \
  --project kpi_assessment
```

### Step 2: Deploy Agents

```bash
# Deploy all agents with memory
antigravity deploy agents \
  --config agents/kpi_assessment.yaml \
  --memory-enabled \
  --memory-backend memvid
```

### Step 3: Run Assessment

```python
# In Antigravity workflow
from antigravity.agents import OrchestratorAgent

async def run_kpi_assessment():
    orchestrator = OrchestratorAgent(
        name="KPIOrchestrator",
        company_id="company_123",
        memory_backend="memvid"
    )
    
    result = await orchestrator.run_full_assessment({
        'csrd': 'documents/csrd.pdf',
        'annual': 'documents/annual.pdf',
        'sustainability': 'documents/sustainability.pdf',
        'third_party': 'documents/third_party_opinion.pdf',
        'transition_plan': 'documents/transition_plan.pdf'
    })
    
    return result
```

---

## üß† HOW MEMORY MAKES AGENTS "THINK LIKE BANKERS"

### Without Memory (Old System)
```
Agent 1: Reads document ‚Üí Extract baseline ‚Üí Report ‚úì
Agent 2: Reads document ‚Üí Extract target ‚Üí Report ‚úì
Agent 9: Build peer comparison ‚Üí How do I know baseline? Ask User ‚ùå
Agent 17: Make decision ‚Üí Where's the evidence? Look at reports ‚ùå
```

### With Memory (New System)
```
Agent 1: Reads document ‚Üí Extract baseline ‚Üí STORE IN MEMORY
Agent 2: Reads document ‚Üí Extract target ‚Üí STORE IN MEMORY
Agent 9: Build peer comparison ‚Üí QUERY MEMORY: "What's baseline?" ‚úì
         ‚Üí All layers build on previous insights
Agent 17: Make decision ‚Üí QUERY ALL MEMORY for complete context
         ‚Üí Reasoning grounded in stored facts
         ‚Üí Can explain every conclusion
```

### Banker Mental Model
```
Banker reads CSRD        ‚Üí Remembers baseline
Banker reads Annual      ‚Üí Remembers financials
Banker reads Peer data   ‚Üí Remembers comparables
Banker thinks            ‚Üí "They're at 65th percentile because..."
Banker decides           ‚Üí MODERATE with evidence

OUR SYSTEM:
Agent 1 reads documents  ‚Üí Stores in memory (like banker reads & remembers)
Agent 4 reads history    ‚Üí Stores in memory (like banker notes credibility)
Agent 9 reads peers      ‚Üí Uses memory for context (like banker compares)
Agent 17 decides         ‚Üí Uses all memory (like banker synthesizes)
```

---

## ‚úÖ SUCCESS METRICS FOR MEMORY-ENABLED SYSTEM

| Metric | Target | How Measured |
|--------|--------|--------------|
| **Memory Accuracy** | 95%+ | Facts in memory match source docs |
| **Context Retrieval** | 95%+ | Agent can find needed facts |
| **Cross-Document Validation** | 95%+ | Detects inconsistencies across docs |
| **Decision Reasoning** | 100% | Each decision cites memory facts |
| **Processing Time** | 4-5 min | Wall clock (memory lookup is fast) |
| **Report Traceability** | 100% | Every report statement ‚Üí memory fact |

---

**This is how you build AI agents that think like bankers: Give them a brain (memory) to remember what they learn.**

End of Guide - Ready to Build in Antigravity! üöÄ